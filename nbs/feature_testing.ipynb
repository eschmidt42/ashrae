{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp feature_testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing features\n",
    "\n",
    "> Testing the impact on features, generated in `preprocessing`, on the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from loguru import logger\n",
    "from fastai.tabular.all import *\n",
    "from ashrae import loading, preprocessing, inspection\n",
    "from sklearn import linear_model, tree, model_selection, ensemble\n",
    "import tqdm\n",
    "import plotly.express as px\n",
    "\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ashrae_data = loading.load_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing the pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tfms_config = {\n",
    "#     'fix_bid_363':{},\n",
    "#     'fix_bid_1099':{'threshold': 10.},\n",
    "#     'remove_bad_meter0_readings_of_first_141days': {},\n",
    "#     'remove_not_summer_0s_meter_2_and_3': {},\n",
    "#     'remove_0s_meter0': {},\n",
    "#     'remove_outliers':{'f':10,'dep_var':'meter_reading'},\n",
    "#     'remove_imputed_weeks':{'dep_var':'meter_reading'},\n",
    "#     'add_dep_var_stats':{},\n",
    "    'add_time_features':{},\n",
    "    'add_weather_features':{'fix_time_offset':True,\n",
    "                            'add_na_indicators':True,\n",
    "                            'impute_nas':True},\n",
    "    'add_building_features':{},\n",
    "#     'add_onehot_encoded':{},\n",
    "}\n",
    "\n",
    "df, df_test, var_names = preprocessing.preprocess_all(ashrae_data, tfms_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing if certain features improve the score beyond the baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training to get a basic idea if the added features do have any benefit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#df = load_df(data_path/'X.parquet')\n",
    "\n",
    "%time\n",
    "#df_test_p = load_df(data_path/'X_test.parquet')\n",
    "\n",
    "%time\n",
    "#var_names = load_var_names(data_path/'var_names.pckl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_tabular_object(df:pd.DataFrame, var_names:dict,\n",
    "                       splits=None, procs:list=None):\n",
    "    if procs is None: procs = []\n",
    "    return TabularPandas(df.copy(), procs,\n",
    "                         var_names['cats'], var_names['conts'],\n",
    "                         y_names=var_names['dep_var'],\n",
    "                         splits=splits)\n",
    "\n",
    "SPLIT_PARAMS = dict(\n",
    "    train_frac = .8,\n",
    "    split_kind = 'time_split_day',\n",
    ")\n",
    "\n",
    "\n",
    "def train_predict(df:pd.DataFrame, var_names:dict,\n",
    "                  model, model_params:dict=None, n_rep:int=3,\n",
    "                  n_samples_train:int=10000,\n",
    "                  n_samples_valid:int=10000,\n",
    "                  procs:list=[Categorify, FillMissing, Normalize],\n",
    "                  split_params:dict=None):\n",
    "\n",
    "    split_params = SPLIT_PARAMS if split_params is None else split_params\n",
    "    y_col = var_names['dep_var']\n",
    "    score_vals = []\n",
    "    model_params = {} if model_params is None else model_params\n",
    "\n",
    "    to = get_tabular_object(df, var_names, procs=procs)\n",
    "\n",
    "    for i in tqdm.tqdm(range(n_rep), total=n_rep, desc='Repetition'):\n",
    "        m = model(**model_params)\n",
    "        splits = preprocessing.split_dataset(df, **split_params)\n",
    "\n",
    "        mask = to.xs.index.isin(splits[0])\n",
    "\n",
    "        _X = to.xs.loc[~mask, :].iloc[:n_samples_train]\n",
    "        _y = to.ys.loc[~mask, y_col].iloc[:n_samples_train]\n",
    "        m.fit(_X.values, _y.values)\n",
    "\n",
    "        _X = to.xs.loc[mask, :].iloc[:n_samples_valid]\n",
    "        _y = to.ys.loc[mask, y_col].iloc[:n_samples_valid]\n",
    "        pred = m.predict(_X.values)\n",
    "        s = torch.sqrt(F.mse_loss(tensor(pred), tensor(_y.values))).item()\n",
    "        score_vals.append({'iter': i, 'rmse loss': s})\n",
    "\n",
    "    return pd.DataFrame(score_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_params = dict(\n",
    "    #split_kind = 'random',\n",
    "    #split_kind = 'time',\n",
    "    #split_kind = 'fix_time',\n",
    "    split_kind = 'time_split_day',\n",
    "    t_train = None,\n",
    "    train_frac = .8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {'n_estimators': 40, 'max_features': 'sqrt',\n",
    "          'n_jobs': -1, 'min_samples_leaf':25}\n",
    "model = ensemble.RandomForestRegressor\n",
    "# params = {}\n",
    "# model = linear_model.LinearRegression\n",
    "n_rep = 21\n",
    "n_samples_train = 100000\n",
    "n_samples_valid = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is not always necessary. Sensible in the case of a linear model to remove categorical values which are not onehot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# to_remove = {'cats':['building_id', 'meter'], 'conts': []}\n",
    "\n",
    "# for k in ['cats', 'conts']:\n",
    "#     var_names[k] = [_v for _v in var_names[k] if _v not in to_remove[k]]\n",
    "# var_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "procs = [Categorify, FillMissing, Normalize]\n",
    "df_rep = train_predict(df.copy(), var_names, model, model_params=model_params, \n",
    "                       n_rep=n_rep, n_samples_train=n_samples_train,\n",
    "                       n_samples_valid=n_samples_valid, procs=procs,\n",
    "                       split_params=split_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rep['rmse loss'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(df_rep, y='rmse loss', range_y=(0, 2.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline model = RandomForest with 20 estimators and sqrt features, training over 100k samples and predicting over 1k\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>input</th>\n",
    "        <th>model</th>\n",
    "        <th>rmse loss</th>\n",
    "        <th>time [s/it]</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>meter and building id only</td>\n",
    "        <td>random forest</td>\n",
    "        <td>1.2 - 1.21</td>\n",
    "        <td>10.2</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>using dep_var stats</td>\n",
    "        <td>random forest</td>\n",
    "        <td>1.16 - 1.18</td>\n",
    "        <td>17.3</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>using time stats</td>\n",
    "        <td>random forest</td>\n",
    "        <td>1.2 - 1.21</td>\n",
    "        <td>13.2 - 13.7</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>using building info</td>\n",
    "        <td>random forest</td>\n",
    "        <td>1.19</td>\n",
    "        <td>17 - 18</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>using weather (+ building) info</td>\n",
    "        <td>random forest</td>\n",
    "        <td>1.13 - 1.139</td>\n",
    "        <td>14.6 - 15</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>using all above</td>\n",
    "        <td>random forest</td>\n",
    "        <td>1.19 - 1.21</td>\n",
    "        <td>20 - 26</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>removing leading 0s in `dep_var`</td>\n",
    "        <td>random forest</td>\n",
    "        <td>.36 - .37</td>\n",
    "        <td>4</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>removing trailing 0s in `dep_var`</td>\n",
    "        <td>random forest</td>\n",
    "        <td>1.2</td>\n",
    "        <td>4</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>removing empty weeks before the first full week</td>\n",
    "        <td>random forest</td>\n",
    "        <td>1.16</td>\n",
    "        <td>4</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>meter only</td>\n",
    "        <td>linear model</td>\n",
    "        <td>2.2</td>\n",
    "        <td>5</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>meter + hour</td>\n",
    "        <td>linear model</td>\n",
    "        <td>2.1</td>\n",
    "        <td>5</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>meter reading stats only (meter, building_id, hour)</td>\n",
    "        <td>linear model</td>\n",
    "        <td>1.23 - 1.24 / 1.68 - 1.7</td>\n",
    "        <td>5</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>meter + meter reading stats (meter, building_id, hour)</td>\n",
    "        <td>linear model</td>\n",
    "        <td>1.51 - 1.52</td>\n",
    "        <td>5</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>meter reading stats (meter, building_id, hour)</td>\n",
    "        <td>random forest</td>\n",
    "        <td>0.58 - 0.6</td>\n",
    "        <td>5</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>meter + meter reading stats (meter, building_id, hour)</td>\n",
    "        <td>random forest</td>\n",
    "        <td>1.21 - 1.22</td>\n",
    "        <td>5</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing `dep_var` distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "splits = preprocessing.split_dataset(df, **split_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "to = get_tabular_object(df, var_names, splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_train = 100_000\n",
    "n_samples_valid = 100_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "params = {'n_estimators': 100, 'max_features': 'sqrt',\n",
    "          'min_samples_leaf':5}\n",
    "model = ensemble.RandomForestRegressor\n",
    "m = model(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "_X = to.train.xs.sample(n_samples_train, replace=True).values\n",
    "_y = to.train.ys.sample(n_samples_train, replace=True).values.ravel()\n",
    "m.fit(_X, _y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "_X = to.valid.xs.sample(n_samples_valid, replace=True).values\n",
    "_y = to.valid.ys.sample(n_samples_valid, replace=True).values.ravel()\n",
    "pred = m.predict(_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert np.isfinite(_y).all() and np.isfinite(pred).all()\n",
    "assert _y.shape == pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def hist_plot_preds(y0:np.ndarray, y1:np.ndarray,\n",
    "                    label0:str='y0', label1:str='y1'):\n",
    "    res = pd.concat(\n",
    "        (\n",
    "            pd.DataFrame({\n",
    "                'y': y0,\n",
    "                'set': [label0] * len(y0)\n",
    "            }),\n",
    "            pd.DataFrame({\n",
    "                'y':y1,\n",
    "                'set': [label1] * len(y1)\n",
    "            })\n",
    "        ),\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "    return px.histogram(res, x='y', color='set', marginal='box',\n",
    "                        barmode='overlay', histnorm='probability density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_plot_preds(_y, pred, label0='truth (valid)', label1='prediction (valid)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting confidently wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BoldlyWrongTimeseries:\n",
    "    def __init__(self, xs, y_true, y_pred, info:pd.DataFrame=None):\n",
    "        if info is None:\n",
    "            self.df = xs.loc[:,['meter', 'building_id', 'timestamp']].copy()\n",
    "        else:\n",
    "            assert all([v in info.columns.values for v in ['meter', 'building_id', 'timestamp']])\n",
    "            self.df = xs.join(info)\n",
    "\n",
    "        for col in ['meter', 'building_id']:\n",
    "            self.df[col] = self.df[col].astype('category')\n",
    "            self.df[col].cat.set_categories(sorted(self.df[col].unique()),\n",
    "                                            ordered=True, inplace=True)\n",
    "\n",
    "        self.df['y_true'] = y_true\n",
    "        self.df['y_pred'] = y_pred\n",
    "        self.compute_misses()\n",
    "\n",
    "    def compute_misses(self):\n",
    "        fun = lambda x: np.sqrt(np.mean(x**2))\n",
    "        self.miss = (self.df.assign(difference=lambda x: x['y_pred']-x['y_true'])\n",
    "                     .groupby(['building_id', 'meter'])\n",
    "                     .agg(loss=pd.NamedAgg(column='difference', aggfunc=fun))\n",
    "                     .dropna()\n",
    "                     .sort_values('loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "_X = to.valid.xs \n",
    "_y = to.valid.ys.values.ravel() \n",
    "pred = m.predict(to.valid.xs.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert _y.shape == pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "bwt = BoldlyWrongTimeseries(to.valid.xs.join(df.loc[:,['building_id', 'meter','timestamp']], lsuffix='to_'), \n",
    "                            _y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "if loading.N_TRAIN is None: assert len(bwt.miss) == 2380"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding plotting capability based on the loss or meter/building id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def plot_boldly_wrong(self:BoldlyWrongTimeseries,\n",
    "                      nth_last:int=None,\n",
    "                      meter:int=None, bid:int=None):\n",
    "\n",
    "    assert (meter is not None and bid is not None) or (nth_last is not None)\n",
    "\n",
    "    if nth_last is not None:\n",
    "        ix = self.miss.iloc[[nth_last],:]\n",
    "        meter = ix.index[0][1]\n",
    "        bid = ix.index[0][0]\n",
    "        loss = ix[\"loss\"].values[0]\n",
    "    else:\n",
    "        ix = self.miss.xs((bid,meter))\n",
    "        loss = ix.values[0]\n",
    "\n",
    "\n",
    "    df_plot = self.df.loc[(self.df['meter']==int(meter)) & (self.df['building_id']==int(bid))]\n",
    "    df_plot = pd.concat((\n",
    "        df_plot[['timestamp', 'y_true']].rename(columns={'y_true':'y'}).assign(label='true'),\n",
    "        df_plot[['timestamp', 'y_pred']].rename(columns={'y_pred':'y'}).assign(label='pred')),\n",
    "        ignore_index=True\n",
    "    )\n",
    "    return df_plot.plot(kind='scatter', x='timestamp',\n",
    "                        y='y', color='label', opacity=.4,\n",
    "                        title=f'pos {nth_last}: meter = {meter}, building_id = {bid}<br>loss = {loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bwt.plot_boldly_wrong(nth_last=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bwt.plot_boldly_wrong(meter=2, bid=1099)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding widgets for interactive exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def init_widgets(self:BoldlyWrongTimeseries):\n",
    "    self.int_txt_loss = widgets.IntText(min=-len(self.miss), max=len(self.miss),\n",
    "                                        description='Position', value=-1)\n",
    "    self.int_txt_meter = widgets.IntText(min=self.df['meter'].min(), max=self.df['meter'].max(),\n",
    "                                         description='Meter')\n",
    "    self.int_txt_bid = widgets.IntText(min=self.df['building_id'].min(), max=self.df['building_id'].max(),\n",
    "                                       description='building id')\n",
    "    self.run_btn = widgets.Button(description='plot')\n",
    "    self.switch_btn = widgets.Checkbox(description='Loss-based', value=True)\n",
    "    self.run_btn.on_click(self.click_boldly_wrong)\n",
    "    self.out_wdg = widgets.Output()\n",
    "\n",
    "@patch\n",
    "def run_boldly(self:BoldlyWrongTimeseries):\n",
    "    if not hasattr(self, 'switch_btn'):\n",
    "        self.init_widgets()\n",
    "    return widgets.VBox([self.switch_btn, self.int_txt_loss,\n",
    "                         self.int_txt_meter, self.int_txt_bid,\n",
    "                         self.run_btn, self.out_wdg])\n",
    "\n",
    "@patch\n",
    "def click_boldly_wrong(self:BoldlyWrongTimeseries, change):\n",
    "    self.out_wdg.clear_output()\n",
    "    nth_last = None if self.switch_btn.value == False else self.int_txt_loss.value\n",
    "    meter = None if self.switch_btn.value == True else self.int_txt_meter.value\n",
    "    bid = None if self.switch_btn.value == True else self.int_txt_bid.value\n",
    "    with self.out_wdg:\n",
    "        print(f'nth_last {nth_last} meter {meter} bid {bid}')\n",
    "        try:\n",
    "            self.plot_boldly_wrong(nth_last=nth_last, meter=meter, bid=bid).show()\n",
    "        except:\n",
    "            raise ValueError(f'nth_last {nth_last} meter {meter} bid {bid} not a valid combination! Likely due to missing meter/bid combination')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bwt.run_boldly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38_fastai]",
   "language": "python",
   "name": "conda-env-py38_fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "255px",
    "width": "272px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

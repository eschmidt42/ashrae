{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling meter readings\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import typing\n",
    "\n",
    "from sklearn import linear_model, tree, model_selection, ensemble\n",
    "\n",
    "from fastai.tabular.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = sorted([base_path/v for v in os.listdir(base_path) if v.endswith('.csv')])\n",
    "csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = csvs[3]\n",
    "train_weather_csv = csvs[-1]\n",
    "test_csv = csvs[2]\n",
    "test_weather_csv = csvs[-2]\n",
    "meta_csv = csvs[0]\n",
    "\n",
    "train_csv, train_weather_csv, test_csv, test_weather_csv, meta_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def numpy_evaluate(y_true:np.ndarray, y_pred:np.ndarray): return np.sqrt(np.mean((y_pred  - y_true)**2))\n",
    "\n",
    "def evaluate_torch(y_true:torch.Tensor, y_pred:torch.Tensor): return torch.sqrt(torch.mean((y_pred - y_true)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train = pd.read_csv(train_csv, parse_dates=['timestamp'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test = pd.read_csv(test_csv, parse_dates=['timestamp'])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "weather_train = pd.read_csv(train_weather_csv, parse_dates=['timestamp'])\n",
    "weather_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "weather_test = pd.read_csv(test_weather_csv, parse_dates=['timestamp'])\n",
    "weather_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "building = pd.read_csv(meta_csv)\n",
    "building.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the model input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metering_input_cols = ['meter'] # 'building_id', 'timestamp']\n",
    "output_col = 'meter_reading'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_Xy(metering:pd.DataFrame,\n",
    "           metering_input_cols:typing.List[str],\n",
    "           output_col:str='meter_reading',\n",
    "           is_train:bool=True):\n",
    "    \n",
    "    X = metering.loc[:,metering_input_cols]\n",
    "    if is_train:\n",
    "        y = np.log(1+metering[output_col].values.ravel())\n",
    "        \n",
    "    if is_train:\n",
    "        return X, y\n",
    "    return X, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X, y = get_Xy(train, metering_input_cols=metering_input_cols,\n",
    "              is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.values.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:5], y_train[:5], X_test[:5], y_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = m.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "numpy_evaluate(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "numpy_evaluate(y_test, m.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding:\n",
    "- Linear model + meter as input only + random 80-20 split  $\\Rightarrow$ 2.14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fastai overkill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radically merging all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def radical_merging(df:pd.DataFrame, building:pd.DataFrame, \n",
    "                    weather:pd.DataFrame, n_sample:int=None,\n",
    "                    training:bool=True):\n",
    "    \n",
    "    tmp = df.copy(deep=True)\n",
    "\n",
    "    bid_col = 'building_id'\n",
    "    sid_col = 'site_id'\n",
    "    time_col = 'timestamp'\n",
    "    target_col = 'meter_reading'\n",
    "    \n",
    "    categorical = ['meter', 'primary_use', 'cloud_coverage'] # bid_col, sid_col\n",
    "    continuous = ['square_feet', 'year_built', 'floor_count', \n",
    "                  'air_temperature', 'dew_temperature',\n",
    "                  'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction',\n",
    "                  'wind_speed']\n",
    "\n",
    "    x_cols = [bid_col, 'meter', target_col, time_col] if training \\\n",
    "            else [bid_col, 'meter', time_col]\n",
    "    X = tmp.loc[:,x_cols].copy()\n",
    "\n",
    "    X = pd.merge(X, building, on=bid_col, how='left')\n",
    "    X = pd.merge(X, weather, on=[sid_col, time_col], how='left')\n",
    "\n",
    "    #return_cols =  categorical + continuous + [target_col,]  # time_col\n",
    "\n",
    "    #X = X.loc[:,return_cols]\n",
    "    if n_sample is not None:\n",
    "        X = X.sample(n_sample)\n",
    "        \n",
    "    if training:\n",
    "        X[target_col] = np.log(X[target_col] + 1)\n",
    "        \n",
    "    X = add_datepart(X, time_col)\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    categorical.extend(['timestampMonth', 'timestampWeek', 'timestampDay',\n",
    "                        'timestampDayofweek', 'timestampDayofyear', 'timestampIs_month_end',\n",
    "                        'timestampIs_month_start', 'timestampIs_quarter_end',\n",
    "                        'timestampIs_quarter_start', 'timestampIs_year_end',\n",
    "                        'timestampIs_year_start'])\n",
    "    \n",
    "    continuous.extend(['timestampYear', 'timestampElapsed'])\n",
    "        \n",
    "    X = X.loc[:, [col for col in X.columns.values if col not in [time_col]]]\n",
    "    \n",
    "    missing_cont = [col for col in continuous if col not in X.columns]\n",
    "    missing_cat = [col for col in categorical if col not in X.columns]\n",
    "    assert len(missing_cat) == 0, f'{missing_cat} not in X!'\n",
    "    assert len(missing_cont) == 0, f'{missing_cont} not in X!'\n",
    "    \n",
    "    X.loc[:,continuous] = X.loc[:,continuous].astype(float)\n",
    "    X.loc[:,categorical] = X.loc[:,categorical].astype('category')\n",
    "    \n",
    "    return X, continuous, categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_sample = 10000\n",
    "X, continuous, categorical = radical_merging(train.copy(), building, weather_train,\n",
    "                    n_sample=n_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_test, _, _ = radical_merging(test.copy(), building, weather_test,\n",
    "                    n_sample=None, training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: fix pd.merge MemoryError: in line 24 \n",
    "MemoryError: Unable to allocate 2.17 GiB for an array with shape (7, 41697600) and data type float64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous, categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def split_dataset(X:pd.DataFrame, split_kind:str='random',\n",
    "                  train_frac:float=8):\n",
    "    \n",
    "    def random_split():\n",
    "        n_train = int(len(X)*train_frac)\n",
    "        train_bool = X.index.isin(np.random.choice(X.index.values, size=n_train, replace=False))\n",
    "        return train_bool\n",
    "    \n",
    "    def time_split():\n",
    "#        print(X.columns)\n",
    "        time_col = 'timestampElapsed'\n",
    "        ts = X[time_col].sort_values(ascending=True)\n",
    "#        print(ts)\n",
    "        ix = int(len(X)*train_frac)\n",
    "#        print('ix', ix)\n",
    "        threshold_t = ts.iloc[ix:].values[0]\n",
    "#        print('threshold_t', threshold_t)\n",
    "        return X[time_col] < threshold_t\n",
    "    \n",
    "    split_funs = {\n",
    "        'random': random_split,\n",
    "        'time': time_split,\n",
    "    }\n",
    "    \n",
    "    assert split_kind in split_funs\n",
    "    train_bool = split_funs[split_kind]()\n",
    "    \n",
    "    train_idx = np.where(train_bool)[0]\n",
    "    valid_idx = np.where(~train_bool)[0]\n",
    "\n",
    "    return (list(train_idx), list(valid_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "split_kind = 'random'\n",
    "#split_kind = 'time'\n",
    "splits = split_dataset(X, split_kind=split_kind, train_frac=.8)\n",
    "#splits=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(X.iloc[splits[0]].loc[:, 'timestampMonth'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Super simplistic input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "procs = [Categorify, FillMissing, Normalize]\n",
    "to = TabularPandas(X, procs, ['meter'],\n",
    "                   [], y_names='meter_reading', splits=splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "procs = [Categorify, FillMissing, Normalize]\n",
    "to = TabularPandas(X.copy(), procs, [], #categorical,\n",
    "                   continuous, \n",
    "                   y_names='meter_reading', splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to.train.xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to.train.ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ensemble.RandomForestRegressor(n_estimators=100, max_features=.75, criterion='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "m.fit(to.train.xs, to.train.ys.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_torch(torch.from_numpy(to.valid.ys.values), \n",
    "               torch.from_numpy(m.predict(to.valid.xs.values).ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling with fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = to.dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_range = [np.min([to.train.ys.values.min(), to.valid.ys.values.min()]),\n",
    "           np.max([to.train.ys.values.max(), to.valid.ys.values.max()]),]\n",
    "y_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_range = [to.train.ys.values.min(),\n",
    "           to.train.ys.values.max()]\n",
    "y_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(dls, y_range=y_range, layers=[500,250],\n",
    "                        n_out=1, loss_func=evaluate_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(5, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, targs = learn.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_torch(targs, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = X.iloc[:50].copy()\n",
    "test = test.drop('meter_reading', axis=1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = X_test.head(100).copy()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = learn.dls.test_dl(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl.xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.get_preds(dl=test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**randomly splitting**\n",
    "    \n",
    "Finding (modified target values, all info = info except time):\n",
    "- Linear:\n",
    "    - meter only @100k: 2.1\n",
    "    - all info minus time @100k: 2.3\n",
    "    - all info incl time @100k: 2.32\n",
    "    - all info incl time + ids @100k: 2.32\n",
    "- RandomForest:\n",
    "    - meter only @100k: 2.2\n",
    "    - all info minus time @100k: 2.7\n",
    "    - all info incl time @100k: 2.74\n",
    "    - all info incl time + ids @100k: 2.82\n",
    "- tabular_learner:\n",
    "    - meter only @100k: 2.1\n",
    "    - all info minus time @100k: 1.56\n",
    "    - all info incl time @100k: 1.52\n",
    "    - all info incl time + ids @100k: 0.96\n",
    "    \n",
    "**splitting along time**\n",
    "Finding:\n",
    "- Linear:\n",
    "    - meter only @100k: 2.1\n",
    "    - all info minus time @100K: 2.2\n",
    "    - all info incl time @100k: 2.3\n",
    "    - all info incl time + ids @100k: 2.29\n",
    "- RandomForest:\n",
    "    - meter only @100k: 2.1\n",
    "    - all info minus time @100K: 2.7\n",
    "    - all info incl time @100k: 2.52\n",
    "    - all info incl time + ids @100k: 2.62\n",
    "- tabular_learner:\n",
    "    - meter only @100k: 2.06\n",
    "    - all info minus time @100K: 1.62\n",
    "    - all info incl time @100k: 1.62\n",
    "    - all info incl time + ids @100k: 1.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py38_fastai]",
   "language": "python",
   "name": "conda-env-.conda-py38_fastai-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

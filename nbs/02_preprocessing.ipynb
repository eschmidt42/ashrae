{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data\n",
    "\n",
    "> Inspecting any particular irregularities and general preparation of the data for modelling as well as basic model inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import typing\n",
    "import pickle\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from sklearn import linear_model, tree, model_selection, ensemble\n",
    "from ashrae import inspection\n",
    "from fastai.tabular.all import *\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from sklearn import linear_model, tree, model_selection, ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = inspection.get_csvs(data_path)\n",
    "csvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train = inspection.get_core_Xy(csvs['train'])\n",
    "display(train.head(), train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test = inspection.get_core_Xy(csvs['test'])\n",
    "display(test.head(), test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "building = inspection.get_building_X(csvs['building'])\n",
    "display(building.head(), building.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "weather_train = inspection.get_weather_X(csvs['weather_train'])\n",
    "display(weather_train.head(), weather_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "weather_test = inspection.get_weather_X(csvs['weather_test'])\n",
    "display(weather_test.head(), weather_test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "DEP_VAR = 'meter_reading'\n",
    "TIME_COL = 'timestamp'\n",
    "\n",
    "class Processor:\n",
    "    \n",
    "    dep_var_stats:dict = None\n",
    "    \n",
    "    def __call__(self, df_core:pd.DataFrame, df_building:pd.DataFrame=None,\n",
    "                 df_weather:pd.DataFrame=None, dep_var:str=None, time_col:str=None,\n",
    "                 add_time_features:bool=False, add_dep_var_stats:bool=False) -> pd.DataFrame:\n",
    "    \n",
    "        # TODO: \n",
    "        # - add daily features: temperature delta per site_id, total rain fall, ...\n",
    "        # - add global stats: mean, median and so on of dep_var by building_id or type\n",
    "        # - add consumption of the days around the day of interest\n",
    "\n",
    "\n",
    "        # sanity check presence of df_building if df_weather is given\n",
    "        if df_weather is not None:\n",
    "            assert df_building is not None, 'To join the weather info in `df_weather` you need to pass `df_building`.'\n",
    "\n",
    "        self.dep_var = DEP_VAR if dep_var is None else dep_var\n",
    "        self.time_col = TIME_COL if time_col is None else time_col\n",
    "\n",
    "        self.conts, self.cats = [], []\n",
    "\n",
    "        # sanity check if `df` is a test set (dep_var is missing)\n",
    "        self.is_train = self.dep_var in df_core.columns\n",
    "\n",
    "        # core pieces of dependent and independent variables\n",
    "        self.dep_var_new = f'{self.dep_var}_log1p'\n",
    "        if self.is_train:\n",
    "            df_core[self.dep_var_new] = np.log(df_core[self.dep_var].values + 1)\n",
    "        self.cats += ['building_id', 'meter']\n",
    "\n",
    "        # adding basic statistics as features\n",
    "        if add_dep_var_stats:\n",
    "            df_core = self.add_dep_var_stats(df_core)\n",
    "\n",
    "        # adding building information\n",
    "        if df_building is not None:\n",
    "            df_core = self.add_building_features(df_core, df_building)\n",
    "\n",
    "        # adding weather information\n",
    "        if df_weather is not None:\n",
    "            df_core = self.add_weather_features(df_core, df_weather)\n",
    "        \n",
    "        # add timestamp related fields\n",
    "        if add_time_features:\n",
    "            df_core = self.add_time_features(df_core)\n",
    "        \n",
    "        df_core, var_names = self.cleanup(df_core)\n",
    "        return df_core, var_names\n",
    "    \n",
    "    \n",
    "    def add_dep_var_stats(self, df_core:pd.DataFrame):\n",
    "        assert self.is_train or self.dep_var_stats is not None\n",
    "        if self.is_train: \n",
    "            self.dep_var_stats = dict()\n",
    "        funs = {\n",
    "            'median': lambda x: torch.median(tensor(x)).item(),\n",
    "            'mean': lambda x: torch.mean(tensor(x)).item(),\n",
    "            '5%': lambda x: np.percentile(x, 5),\n",
    "            '95%': lambda x: np.percentile(x, 95),\n",
    "        }\n",
    "        for name, fun in funs.items():\n",
    "            name = f'{self.dep_var}_{name}'\n",
    "            self.conts.append(name)\n",
    "            \n",
    "            if self.is_train:\n",
    "                value = fun(df_core[self.dep_var].values)\n",
    "                df_core[name] = value\n",
    "                self.dep_var_stats[name] = value\n",
    "            else:\n",
    "                df_core[name] = self.dep_var_stats[name]\n",
    "        return df_core\n",
    "                \n",
    "    def add_time_features(self, df_core:pd.DataFrame):\n",
    "        self.cats.extend(['timestampMonth', 'timestampDay', 'timestampWeek', 'timestampDayofweek',\n",
    "                     'timestampDayofyear', 'timestampIs_month_end', 'timestampIs_month_start',\n",
    "                     'timestampIs_quarter_start', 'timestampIs_quarter_end',\n",
    "                     'timestampIs_year_start', 'timestampIs_year_end',])\n",
    "        return add_datepart(df_core, self.time_col)\n",
    "    \n",
    "    def add_building_features(self, df_core:pd.DataFrame, df_building:pd.DataFrame):\n",
    "        n = len(df_core)\n",
    "        df_core = pd.merge(df_core, df_building, on='building_id', how='left')\n",
    "        assert n == len(df_core)\n",
    "\n",
    "        self.cats.extend(['site_id', 'primary_use'])\n",
    "        self.conts.extend(['square_feet', 'year_built', 'floor_count'])\n",
    "        return df_core\n",
    "    \n",
    "    def add_weather_features(self, df_core:pd.DataFrame, df_weather:pd.DataFrame):\n",
    "        n = len(df_core)\n",
    "        df_core = pd.merge(df_core, df_weather, on=['site_id', 'timestamp'], how='left')\n",
    "        assert n == len(df_core)\n",
    "\n",
    "        self.cats.extend(['cloud_coverage', 'wind_direction'])\n",
    "        self.conts.extend(['air_temperature', 'dew_temperature', 'precip_depth_1_hr',\n",
    "                      'sea_level_pressure', 'wind_speed'])\n",
    "        return df_core\n",
    "    \n",
    "    def cleanup(self, df_core:pd.DataFrame):\n",
    "        # converting cats to category type\n",
    "        for col in self.cats:\n",
    "            df_core[col] = df_core[col].astype('category')\n",
    "\n",
    "        # removing features \n",
    "        to_remove_cols = [self.dep_var, 'timestampYear', self.time_col]\n",
    "        df_core = df_core.drop(columns=[c for c in df_core.columns if c in to_remove_cols])\n",
    "        df_core = df_shrink(df_core, int2uint=True)\n",
    "\n",
    "        var_names = {'conts': self.conts, 'cats': self.cats, 'dep_var': self.dep_var_new}\n",
    "        if not self.is_train:\n",
    "            df_core.set_index('row_id', inplace=True)\n",
    "        missing_cols = [col for col in df_core.columns.values if col not in self.cats + self.conts + [self.dep_var_new]\n",
    "                        and col != 'timestampElapsed']\n",
    "        assert len(missing_cols) == 0, f'Missed to assign columns: {missing_cols} to `conts` or `cats`'\n",
    "        return df_core, var_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_config = dict(\n",
    "    add_time_features = True,\n",
    "    add_dep_var_stats = True,\n",
    "    df_building = building,\n",
    "    df_weather = weather_train\n",
    ")\n",
    "process = Processor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df, var_names = process(train.copy(), \n",
    "                        **process_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_test, _ = process(test.copy(), \n",
    "                     **process_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert len(df_test.columns) + 1 == len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def test_var_names(var_names:dict):\n",
    "    assert isinstance(var_names, dict)\n",
    "    assert 'conts' in var_names and 'cats' in var_names and 'dep_var' in var_names\n",
    "    assert isinstance(var_names['conts'], list) \n",
    "    assert isinstance(var_names['cats'], list) \n",
    "    assert isinstance(var_names['dep_var'], str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_var_names(var_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def store_var_names(data_path:Path, var_names:dict):\n",
    "    fname = data_path/'var_names.pckl'\n",
    "    print(f'Storing var names at: {fname}')\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(var_names, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "store_var_names(data_path, var_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_var_names(fname:Path):\n",
    "    print(f'Reading var names at: {fname}')\n",
    "    with open(fname, 'rb') as f:\n",
    "        var_names = pickle.load(f)\n",
    "    return var_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# var_names = load_var_names(data_path/'var_names.pckl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_var_names(var_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def store_df(path:Path, df:pd.DataFrame): df.to_parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "store_df(data_path/'X.parquet', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "store_df(data_path/'X_test.parquet', df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_df(path:Path): return pd.read_parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# df = load_df(data_path/'X.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing if certain features improve the score beyond the baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training to get a basic idea if the added features do have any benefit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = load_df(data_path/'X.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_test = load_df(data_path/'X_test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "var_names = load_var_names(data_path/'var_names.pckl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_tabular_object(df:pd.DataFrame, var_names:dict,\n",
    "                       splits=None):\n",
    "    procs = [Categorify, FillMissing, Normalize]\n",
    "    return TabularPandas(df.copy(), procs, \n",
    "                         var_names['cats'], var_names['conts'], \n",
    "                         y_names=var_names['dep_var'],\n",
    "                         splits=splits)\n",
    "    return to\n",
    "\n",
    "\n",
    "def train_predict(df:pd.DataFrame, var_names:dict, \n",
    "                  model, params:dict=None, n_rep:int=3,\n",
    "                  n_samples_train:int=10000, \n",
    "                  n_samples_test:int=10000,\n",
    "                  test_size:float=.2):\n",
    "\n",
    "    y_col = var_names['dep_var']\n",
    "    score_vals = []\n",
    "    params = {} if params is None else params\n",
    "    \n",
    "    to = get_tabular_object(df, var_names)\n",
    "    \n",
    "    for i in tqdm.tqdm(range(n_rep), total=n_rep, desc='Repetition'):\n",
    "        \n",
    "        m = model(**params)\n",
    "        \n",
    "        mask = to.xs.index.isin(\n",
    "            np.random.choice(to.xs.index.values, size=int(test_size*len(to.xs)), replace=False)\n",
    "        )\n",
    "        \n",
    "        _X = to.xs.loc[~mask, :].iloc[:n_samples_train]\n",
    "        _y = to.ys.loc[~mask, y_col].iloc[:n_samples_train]\n",
    "        m.fit(_X.values, _y.values)\n",
    "        \n",
    "        _X = to.xs.loc[mask, :].iloc[:n_samples_test]\n",
    "        _y = to.ys.loc[mask, y_col].iloc[:n_samples_test]\n",
    "        pred = m.predict(_X.values)\n",
    "        s = torch.sqrt(F.mse_loss(tensor(pred), tensor(_y.values))).item()\n",
    "        score_vals.append({'iter': i, 'rmse loss': s})\n",
    "    \n",
    "    return pd.DataFrame(score_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': 20, 'max_features': 'sqrt',\n",
    "          'n_jobs': -1}\n",
    "model = ensemble.RandomForestRegressor\n",
    "# params = None\n",
    "# model = linear_model.LinearRegression\n",
    "n_rep = 21\n",
    "n_samples_train = 10000\n",
    "n_samples_test = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_rep = train_predict(df.copy(), var_names, model, params=params, \n",
    "                       n_rep=n_rep, n_samples_train=n_samples_train,\n",
    "                       n_samples_test=n_samples_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rep['rmse loss'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(df_rep, y='rmse loss', range_y=(0, 2.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline model = RandomForest with 20 estimators and sqrt features, training over 100k samples and predicting over 1k\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>input</th>\n",
    "        <th>rmse loss</th>\n",
    "        <th>time [s/it]</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>meter and building id only</td>\n",
    "        <td>1.2 - 1.21</td>\n",
    "        <td>10.2</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>using dep_var stats</td>\n",
    "        <td>1.16 - 1.18</td>\n",
    "        <td>17.3</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>using time stats</td>\n",
    "        <td>1.2 - 1.21</td>\n",
    "        <td>13.2 - 13.7</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>using building info</td>\n",
    "        <td>1.19</td>\n",
    "        <td>17 - 18</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>using weather (+ building) info</td>\n",
    "        <td>1.13 - 1.139</td>\n",
    "        <td>14.6 - 15</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>using all above</td>\n",
    "        <td>1.19 - 1.21</td>\n",
    "        <td>20 - 26</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing `dep_var` distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "to = get_tabular_object(df, var_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = .2\n",
    "n_samples_train = 10000\n",
    "n_samples_test = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mask = to.xs.index.isin(\n",
    "    np.random.choice(to.xs.index.values, size=int(test_size*len(to.xs)), replace=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "params = {'n_estimators': 20, 'max_features': 'sqrt'}\n",
    "model = ensemble.RandomForestRegressor\n",
    "m = model(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "_X = to.xs.loc[~mask, :].iloc[:n_samples_train]\n",
    "_y = to.ys.loc[~mask, var_names['dep_var']].iloc[:n_samples_train]\n",
    "m.fit(_X.values, _y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "_X = to.xs.loc[mask, :].iloc[:n_samples_test]\n",
    "_y = to.ys.loc[mask, var_names['dep_var']].iloc[:n_samples_test]\n",
    "pred = m.predict(_X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def hist_plot_preds(y0:np.ndarray, y1:np.ndarray, \n",
    "                    label0:str='y0', label1:str='y1'):\n",
    "    res = pd.concat(\n",
    "        (\n",
    "            pd.DataFrame({\n",
    "                'y': y0, \n",
    "                'set': [label0] * len(y0)\n",
    "            }),\n",
    "            pd.DataFrame({\n",
    "                'y':y1, \n",
    "                'set': [label1] * len(y1)\n",
    "            })\n",
    "        ),\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "    return px.histogram(res, x='y', color='set', marginal='box',\n",
    "                        barmode='overlay', histnorm='probability density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_plot_preds(_y, pred, label0='train', label1='valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting confidently wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BoldlyWrongTimeseries:\n",
    "    def __init__(self, xs, y_true, y_pred, t:pd.DataFrame=None):\n",
    "        if t is None:\n",
    "            self.df = xs.loc[:,['meter', 'building_id', 'timestampElapsed']].copy()\n",
    "        else:\n",
    "            self.df = xs.loc[:,['meter', 'building_id']].join(t.reset_index().drop_duplicates().set_index('index'))\n",
    "        self.df['y_true'] = y_true\n",
    "        self.df['y_pred'] = y_pred\n",
    "        self.compute_misses(y_true)\n",
    "\n",
    "    def compute_misses(self, y_true):\n",
    "        fun = lambda x: np.mean(x**2)\n",
    "        self.miss = (self.df.assign(difference=lambda x: x['y_pred']-x['y_true'])\n",
    "                     .groupby(['meter', 'building_id'])\n",
    "                     .agg(loss=pd.NamedAgg(column='difference', aggfunc=fun))\n",
    "                     .sort_values('loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "_X = to.xs.loc[mask, :] #.iloc[:n_samples_test]\n",
    "_y = to.ys.loc[mask, var_names['dep_var']] #.iloc[:n_samples_test]\n",
    "pred = m.predict(_X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bwt = BoldlyWrongTimeseries(_X, _y, pred,\n",
    "                            t=df.loc[mask,['timestampElapsed']].copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding plotting capability based on the loss or meter/building id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def plot_boldly_wrong(self:BoldlyWrongTimeseries, \n",
    "                      nth_last:int=None,\n",
    "                      meter:int=None, bid:int=None):\n",
    "    \n",
    "    assert (meter is not None and bid is not None) or (nth_last is not None)\n",
    "    \n",
    "    if nth_last is not None:\n",
    "        ix = self.miss.iloc[[nth_last],:]\n",
    "        meter = ix.index[0][0]\n",
    "        bid = ix.index[0][1]\n",
    "        loss = ix[\"loss\"].values[0]\n",
    "    else:\n",
    "        ix = self.miss.xs((meter, bid))\n",
    "        loss = ix.values[0]\n",
    "        \n",
    "    df_plot = self.df.loc[(self.df['meter']==meter) & (self.df['building_id']==bid)]\n",
    "    df_plot = pd.concat((\n",
    "        df_plot[['timestampElapsed', 'y_true']].rename(columns={'y_true':'y'}).assign(label='true'),\n",
    "        df_plot[['timestampElapsed', 'y_pred']].rename(columns={'y_pred':'y'}).assign(label='pred'))\n",
    "    )\n",
    "    return df_plot.plot(kind='scatter', x='timestampElapsed', \n",
    "                        y='y', color='label', opacity=.4,\n",
    "                        title=f'pos {nth_last}: meter = {meter}, building_id = {bid}<br>loss = {loss:.3f}')\n",
    "    \n",
    "    \n",
    "BoldlyWrongTimeseries.plot_boldly_wrong = plot_boldly_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwt.plot_boldly_wrong(nth_last=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwt.plot_boldly_wrong(meter=1, bid=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding widgets for interactive exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def init_widgets(self:BoldlyWrongTimeseries):\n",
    "    self.int_txt_loss = widgets.IntText(min=-len(self.miss), max=len(self.miss),\n",
    "                                        description='Position', value=-1)\n",
    "    self.int_txt_meter = widgets.IntText(min=self.df['meter'].min(), max=self.df['meter'].max(),\n",
    "                                         description='Meter')\n",
    "    self.int_txt_bid = widgets.IntText(min=self.df['building_id'].min(), max=self.df['building_id'].max(),\n",
    "                                       description='building id')\n",
    "    self.run_btn = widgets.Button(description='plot')\n",
    "    self.switch_btn = widgets.Checkbox(description='Loss-based', value=True)\n",
    "    self.run_btn.on_click(self.click_boldly_wrong)\n",
    "    self.out_wdg = widgets.Output()\n",
    "    \n",
    "@patch\n",
    "def run_boldly(self:BoldlyWrongTimeseries):\n",
    "    if not hasattr(self, 'switch_btn'):\n",
    "        self.init_widgets()\n",
    "    return widgets.VBox([self.switch_btn, self.int_txt_loss, \n",
    "                         self.int_txt_meter, self.int_txt_bid, \n",
    "                         self.run_btn, self.out_wdg])\n",
    "\n",
    "@patch\n",
    "def click_boldly_wrong(self:BoldlyWrongTimeseries, change):\n",
    "    self.out_wdg.clear_output()\n",
    "    nth_last = None if self.switch_btn.value == False else self.int_txt_loss.value\n",
    "    meter = None if self.switch_btn.value == True else self.int_txt_meter.value\n",
    "    bid = None if self.switch_btn.value == True else self.int_txt_bid.value\n",
    "    with self.out_wdg:\n",
    "        print(f'nth_last {nth_last} meter {meter} bid {bid}')\n",
    "        try:\n",
    "            self.plot_boldly_wrong(nth_last=nth_last, meter=meter, bid=bid).show()\n",
    "        except:\n",
    "            raise ValueError(f'nth_last {nth_last} meter {meter} bid {bid} not a valid combination! Likely due to missing meter/bid combination')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwt.run_boldly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py38_fastai]",
   "language": "python",
   "name": "conda-env-.conda-py38_fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

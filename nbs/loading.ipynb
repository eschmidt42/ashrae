{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data\n",
    "\n",
    "> Systematic loading and testing of individual files for the ASHRAE energy predictor competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import typing\n",
    "from loguru import logger\n",
    "\n",
    "from fastcore.all import *\n",
    "from fastai.tabular.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting the `.csv` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "DATA_PATH = Path(\"../data\")\n",
    "N_TRAIN = 10_000 # number of samples to load for the train set\n",
    "N_TEST = 10_000 # number of samples to load for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "CSV_NAMES_MAP = {'building_metadata.csv':'building', \n",
    "                 'test.csv':'test', \n",
    "                 'train.csv':'train', \n",
    "                 'weather_test.csv':'weather_test', \n",
    "                 'weather_train.csv':'weather_train',\n",
    "                 'ashrae-energy-prediction-publicleaderboard.csv': 'public-leaderboard'}\n",
    "\n",
    "@typed\n",
    "def get_csvs(data_path:Path=DATA_PATH, csv_names_map:dict={}) -> dict:\n",
    "    csv_names = CSV_NAMES_MAP if len(csv_names_map) == 0 else csv_names_map\n",
    "    csvs = (data_path.ls()\n",
    "            .filter(lambda x: x.name.endswith('.csv'))\n",
    "            .map_dict(lambda x: csv_names.get(x.name, None)))\n",
    "    logger.info(f'Collected csv paths: {csvs}')\n",
    "    return {v: k for k,v in csvs.items() if v is not None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "csvs = get_csvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert len(csvs) == len(CSV_NAMES_MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading basic meter info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typed\n",
    "def get_meter_data(path:Path, nrows:int=-1) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, parse_dates=['timestamp'])\n",
    "    if nrows > 0: df = df.sample(nrows)\n",
    "    logger.info(f'Loading meter data: {path}')\n",
    "    return df_shrink(df, int2uint=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the core of the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_meter_train = get_meter_data(csvs['train'], nrows=N_TRAIN)\n",
    "display(df_meter_train.head(), df_meter_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_meter_test = get_meter_data(csvs['test'], nrows=N_TEST)\n",
    "display(df_meter_test.head(), df_meter_test.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typed\n",
    "def get_nan_stats(df:pd.DataFrame, col:str) -> pd.Series:\n",
    "    n = df[col].isna().sum()\n",
    "    return pd.Series({'# NaNs': n,\n",
    "                      'col': col,\n",
    "                      'NaNs (%)': 100 * n / len(df)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_nan_stats(df_meter_train, 'meter_reading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typed\n",
    "def show_nans(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    nans = []\n",
    "    for col in df.columns:\n",
    "        nans.append(get_nan_stats(df, col))\n",
    "    return (pd.concat(nans, axis=1).T\n",
    "            .assign(**{\n",
    "                '# NaNs': lambda x: x['# NaNs'].astype(int), \n",
    "                'NaNs (%)': lambda x: x['NaNs (%)'].astype(float)})\n",
    "            .sort_values('# NaNs', ascending=False)\n",
    "            .set_index('col'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "meter_train_nans = show_nans(df_meter_train)\n",
    "meter_train_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typed\n",
    "def test_meter_train_and_test_set(df_train:pd.DataFrame, df_test:pd.DataFrame):\n",
    "    assert len(df_train) == (20216100 if N_TRAIN == -1 else N_TRAIN)\n",
    "    assert len(df_test) == (41697600 if N_TEST == -1 else N_TEST)\n",
    "    assert set(df_train['meter'].unique()) == set(df_test['meter'].unique())\n",
    "    if N_TRAIN > 20216100 and N_TEST > 41697600: \n",
    "        assert set(df_train['building_id'].unique()) == set(df_test['building_id'].unique())\n",
    "    train_nans = show_nans(df_train)\n",
    "    assert np.allclose(train_nans['# NaNs'].values, 0)\n",
    "    test_nans = show_nans(df_test)\n",
    "    assert np.allclose(test_nans['# NaNs'].values, 0)\n",
    "    logger.info('Passed basic meter info tests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%time\n",
    "test_meter_train_and_test_set(df_meter_train, df_meter_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get building info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typed\n",
    "def get_building_data(path:Path=DATA_PATH/'building_metadata.csv') -> pd.DataFrame:\n",
    "    # TODO: year_built and floor_count actually are discrete values but contain nans\n",
    "    # test if 'Int' dtype would work or if it breaks the things downstream\n",
    "    logger.info(f'Loading building data: {path}')\n",
    "    df_building = pd.read_csv(path)\n",
    "    return df_shrink(df_building, int2uint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_building = get_building_data(csvs['building'])\n",
    "df_building.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typed\n",
    "def test_building(df_building:pd.DataFrame, df_core:pd.DataFrame):\n",
    "    assert df_building['building_id'].nunique() == len(df_building)\n",
    "    if N_TRAIN == -1: assert set(df_core['building_id'].unique()) == set(df_building['building_id'].unique())\n",
    "    building_nans = show_nans(df_building)\n",
    "    assert np.allclose(building_nans['# NaNs'].values, [1094, 774, 0, 0, 0, 0])\n",
    "    logger.info('Passed basic building info test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_building(df_building, df_meter_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get weather info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typed\n",
    "def get_weather_data(path:Path=DATA_PATH/'weather_train.csv') -> pd.DataFrame:\n",
    "    # TODO: cloud_coverage, wind_direction could be Int\n",
    "    logger.info(f'Loading weather data: {path}')\n",
    "    df_weather = pd.read_csv(path, parse_dates=['timestamp'])\n",
    "    return df_shrink(df_weather, int2uint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_weather_train = get_weather_data(csvs['weather_train'])\n",
    "df_weather_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typed\n",
    "def test_weather(df_weather:pd.DataFrame, df_building:pd.DataFrame):\n",
    "    assert set(df_weather['site_id'].unique()) == set(df_building['site_id'].unique())\n",
    "    weather_nans = show_nans(df_weather)\n",
    "    assert weather_nans.loc['site_id', '# NaNs'] == 0\n",
    "    assert weather_nans.loc['timestamp', '# NaNs'] == 0\n",
    "    logger.info('Passed basic weather tests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_weather(df_weather_train, df_building)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_weather_test = get_weather_data(csvs['weather_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert len(df_weather_test) != len(df_weather_train)\n",
    "test_weather(df_weather_test, df_building)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing all the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typed\n",
    "def load_all(data_path:Path=DATA_PATH) -> dict:\n",
    "    'Locates csvs, loads them and performs basic sanity checks'\n",
    "    # locating csvs\n",
    "    csvs = get_csvs(data_path)\n",
    "    \n",
    "    # loading data\n",
    "    ashrae_data = {}\n",
    "    \n",
    "    ## loading meter readings\n",
    "    ashrae_data['meter_train'] = get_meter_data(csvs['train'], nrows=N_TRAIN)\n",
    "    ashrae_data['meter_test'] = get_meter_data(csvs['test'], nrows=N_TEST)\n",
    "    test_meter_train_and_test_set(ashrae_data['meter_train'], ashrae_data['meter_test'])\n",
    "    \n",
    "    # loading building info\n",
    "    ashrae_data['building'] = get_building_data(csvs['building'])\n",
    "    test_building(ashrae_data['building'], ashrae_data['meter_train'])\n",
    "    \n",
    "    # loading weather data\n",
    "    ashrae_data['weather_train'] = get_weather_data(csvs['weather_train'])\n",
    "    test_weather(ashrae_data['weather_train'], ashrae_data['building'])\n",
    "    ashrae_data['weather_test'] = get_weather_data(csvs['weather_test'])\n",
    "    test_weather(ashrae_data['weather_test'], ashrae_data['building'])\n",
    "    \n",
    "    return ashrae_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ashrae_data = load_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38_fastai]",
   "language": "python",
   "name": "conda-env-py38_fastai-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

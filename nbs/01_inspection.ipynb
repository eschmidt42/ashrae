{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspection of the data\n",
    "\n",
    "> Basic inspection of the dependent variable, `dep_var`, in train and test set and preparation of the preprocessing step in `02_preprocessing.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from fastcore.utils import *\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import typing\n",
    "\n",
    "from fastai.tabular.all import * \n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting the `.csv` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "CSV_NAMES = ['building', 'sample_submission', 'test', 'train', 'weather_test', 'weather_train']\n",
    "\n",
    "def get_csvs(data_path:Path, csv_names:typing.List[str]=None) -> typing.Dict[str, Path]:\n",
    "    csvs = sorted([v for v in data_path.ls() if v.name.endswith('.csv')])\n",
    "    csv_names = CSV_NAMES if csv_names is None else csv_names\n",
    "    return dict(zip(csv_names, csvs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = get_csvs(data_path)\n",
    "csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert len(csvs) == len(CSV_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting basic $X$ and $y$ in train and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to inspect:\n",
    "- NaNs\n",
    "- $y$ distribution\n",
    "- compressibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get  compressed $X$ and $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_core_Xy(path:Path, nrows:int=None) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, parse_dates=['timestamp'], nrows=nrows)\n",
    "    return df_shrink(df, int2uint=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the core of the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train = get_core_Xy(csvs['train'])\n",
    "display(train.head(), train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test = get_core_Xy(csvs['test'])\n",
    "display(test.head(), test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert set(train['meter'].unique()) == set(test['meter'].unique())\n",
    "assert set(train['building_id'].unique()) == set(test['building_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def show_nans(df:pd.DataFrame):\n",
    "    nans = []\n",
    "    for col in df.columns:\n",
    "        nans.append({\n",
    "            'nans count': df[col].isna().sum(), \n",
    "            'col':col,\n",
    "            'nans %': df[col].isna().sum() / len(df) * 100,\n",
    "        })\n",
    "    return pd.DataFrame(nans).sort_values('nans count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_nans = show_nans(train)\n",
    "train_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert np.allclose(train_nans['nans count'].values, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_nans = show_nans(test)\n",
    "test_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert np.allclose(test_nans['nans count'].values, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_var = 'meter_reading'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[dep_var].describe(percentiles=[.05,.10,.25,.50,.75,.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding: ~10% of all `dep_var` values are in the vicinity of 0 and there is an outlier at 2.19e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train[dep_var] > 1e6).sum() / len(train) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['logp1'] = np.log10(train[dep_var] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "px.histogram(train.sample(10000), x='logp1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "px.histogram(train.sample(10000), x='logp1', facet_row='meter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding:\n",
    "- abnormally many 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('meter')[dep_var].describe(percentiles=[.05,.10,.25,.50,.75,.95]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding:\n",
    "- 10% of meter 1 & 2 are near 0\n",
    "- 25% of meter 3 are near 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seasonality of 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.isclose(train[dep_var], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[mask, 'timestamp'].sample(10000).dt.hour.plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(train.loc[mask, :]\n",
    "             .sample(10000)\n",
    "             .assign(hour=lambda x: x['timestamp'].dt.month),\n",
    "             x='hour',\n",
    "             facet_row='meter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding:\n",
    "- hour, day of week, day of month: not really a trend on global or meter level for the frequency of zeros\n",
    "- month: more zeros during summer for meter 2 & 3, less zeros for meter 0 from month 6 onwards, less zeros for meter 1 between month 6 and 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Site, building and meter frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['meter'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['meter'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['building_id'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['building_id'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the building info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_building_X(path:Path):\n",
    "    # TODO: year_built and floor_count actually are discrete values but contain nans\n",
    "    # test if 'Int' dtype would work or if it breaks the things downstream\n",
    "    df_building = pd.read_csv(path)\n",
    "    return df_shrink(df_building, int2uint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_building = get_building_X(csvs['building'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert df_building['building_id'].nunique() == len(df_building)\n",
    "assert set(train['building_id'].unique()) == set(df_building['building_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_building.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_nans = show_nans(df_building)\n",
    "building_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert np.allclose(building_nans['nans count'].values, [1094, 774, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting weather info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_weather_X(path:Path):\n",
    "    # TODO: cloud_coverage, wind_direction could be Int\n",
    "    df = pd.read_csv(path, parse_dates=['timestamp'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_weather_train = get_weather_X(csvs['weather_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert set(df_weather_train['site_id'].unique()) == set(df_building['site_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_nans = show_nans(df_weather_train)\n",
    "weather_train_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert np.allclose(weather_train_nans.iloc[-2:]['nans count'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_weather_test = get_weather_X(csvs['weather_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert set(df_weather_test['site_id'].unique()) == set(df_building['site_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_test_nans = show_nans(df_weather_test)\n",
    "weather_test_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert np.allclose(weather_test_nans.iloc[-2:]['nans count'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "len(train.join(df_building.set_index('building_id'), on='building_id',\n",
    "           how='left').join(df_weather_train.set_index(['site_id', 'timestamp']), on=['site_id', 'timestamp'], how='left'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "len(pd.merge(pd.merge(train, df_building, on='building_id', how='left'),\n",
    "    df_weather_train, on=['site_id', 'timestamp'], how='left'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train = pd.read_csv(train_csv, parse_dates=['timestamp'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test = pd.read_csv(test_csv, parse_dates=['timestamp'])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train), len(test), len(test)/len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding:\n",
    "- test samples ~2x train samples\n",
    "- train samples ~2mio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "weather_train = pd.read_csv(train_weather_csv)\n",
    "weather_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "weather_test = pd.read_csv(test_weather_csv)\n",
    "weather_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "building = pd.read_csv(meta_csv)\n",
    "building.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train), len(weather_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many data points each building, meter, site, building type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['building_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "px.box(train.groupby('building_id').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train.groupby('meter').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "px.box(weather.groupby('site_id').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train.join(building.loc[:,['building_id', 'primary_use']], on='building_id', rsuffix='_building').groupby('primary_use').size().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding: \n",
    "- buildings vary with data points significantly\n",
    "- sites vary barely with data points\n",
    "- meter vary with data points by 10x between least and most data points\n",
    "- `primary_use`: Religious worship 32k, Education 8.1mio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomalies: meter reading, weather, building properties, gaps in the time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### meter readings (output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### counting number of meter readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('meter').()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['timestamp'].unique()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_ts = pd.date_range(train['timestamp'].min(), train['timestamp'].max(), freq='60T')\n",
    "ideal_ts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ideal_ts), train['timestamp'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding: \n",
    "- the number of timestamps in the training set matches the expected number of timestamps of 1hour intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = train.groupby('timestamp').size()\n",
    "test_counts = test.groupby('timestamp').size()\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Scatter(x=train_counts.index, y=train_counts.values, name='train'),\n",
    "    go.Scatter(x=test_counts.index, y=test_counts.values, name='test'),\n",
    "], layout=go.Layout(title='Data point count v time: train v test'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding: \n",
    "- meter counts inconsistent vs time for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### meter value trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['meter'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No NaNs in the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_counts = (train.dropna(subset=['meter']).groupby(['timestamp', 'meter'])\n",
    "                .agg(**{\n",
    "                    'mean': pd.NamedAgg('meter_reading', np.mean),\n",
    "                    'median': pd.NamedAgg('meter_reading', np.median),\n",
    "                    '5%': pd.NamedAgg('meter_reading', lambda x: np.percentile(x, 5)),\n",
    "                    '95%': pd.NamedAgg('meter_reading', lambda x: np.percentile(x, 95)),\n",
    "                }).unstack(level=-1))\n",
    "train_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for meter in [0,1,2,3]:\n",
    "    tmp = train_counts.loc[:,pd.IndexSlice[:,meter]]\n",
    "    tmp.columns = tmp.columns.droplevel(level=1)\n",
    "    tmp = tmp.reset_index()\n",
    "    \n",
    "    fig = go.Figure(data=[\n",
    "        go.Scatter(x=tmp['timestamp'], y=tmp['5%'], mode='lines', name='5%'),\n",
    "        go.Scatter(x=tmp['timestamp'], y=tmp['95%'], mode='lines', fill='tonexty', name='5% - 95%'),\n",
    "        go.Scatter(x=tmp['timestamp'], y=tmp['mean'], mode='lines', name='mean'),\n",
    "        go.Scatter(x=tmp['timestamp'], y=tmp['median'], mode='lines', name='median'),\n",
    "    ], layout=go.Layout(title=f'meter: {meter}'))\n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "meter map: `{0: electricity, 1: chilledwater, 2: steam, 3: hotwater}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding:\n",
    "- the 4 meter types have quite different time behaviors\n",
    "- meters 0 & 1 have a seasonabl behavior based on the weekday (but much stronger for meter 0 than 1)\n",
    "- meter 2 has measurement anomalies has significant anomalous time periods  (median exceeds the 95% values)\n",
    "- meter 2 & 3 have seasonal effect based on the time of year it seems "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for meter in [0,1,2,3]:\n",
    "    tmp = train.loc[train['meter']==meter, :].sort_values('meter_reading', ascending=False)\n",
    "    print('meter', meter)\n",
    "    display(tmp.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### building properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building['in_train'] = building['building_id'].isin(train['building_id'])\n",
    "building['in_test'] = building['building_id'].isin(test['building_id'])\n",
    "building.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building.groupby(['in_train', 'in_test']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(building['square_feet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(building['year_built'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(building['floor_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding:\n",
    "- `floor_count`, `year_built` and `square_feet` seem reasonable overall\n",
    "- all buildings in train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weather properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = weather_train.columns.values[2:]\n",
    "weather_train.loc[:,cols].isna().sum() / len(weather_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding:\n",
    "- `cloud_coverage` 50% NaNs\n",
    "- `precip_depth_1_hr` 35.9% NaNs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for col in cols:\n",
    "    tmp = (weather_train.dropna(subset=[col]).groupby(['timestamp'])\n",
    "              .agg(**{\n",
    "                  'mean': pd.NamedAgg(col, np.mean,),\n",
    "                  'median': pd.NamedAgg(col, np.median),\n",
    "                  '5%': pd.NamedAgg(col, lambda x: np.percentile(x, 5)),\n",
    "                  '95%': pd.NamedAgg(col, lambda x: np.percentile(x, 95)),\n",
    "              }).reset_index())\n",
    "    display(tmp.head())\n",
    "    \n",
    "    fig = go.Figure(data=[\n",
    "        go.Scatter(x=tmp['timestamp'], y=tmp['5%'], mode='lines', name='5%'),\n",
    "        go.Scatter(x=tmp['timestamp'], y=tmp['95%'], mode='lines', fill='tonexty', name='5% - 95%'),\n",
    "        go.Scatter(x=tmp['timestamp'], y=tmp['mean'], mode='lines', name='mean'),\n",
    "        go.Scatter(x=tmp['timestamp'], y=tmp['median'], mode='lines', name='median'),\n",
    "    ], layout=go.Layout(title=f'column: {col}'))\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding:\n",
    "- temperatures $\\Rightarrow$ buildings predomonantly in the northern hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38_fastai]",
   "language": "python",
   "name": "conda-env-py38_fastai-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspection of the data\n",
    "\n",
    "> Basic inspection of the dependent variable, `dep_var`, in train and test set and preparation of the preprocessing step in `02_preprocessing.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from fastcore.utils import *\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import typing\n",
    "\n",
    "from fastai.tabular.all import * \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting the `.csv` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "CSV_NAMES = ['building', 'sample_submission', 'test', 'train', 'weather_test', 'weather_train']\n",
    "\n",
    "def get_csvs(data_path:Path, csv_names:typing.List[str]=None) -> typing.Dict[str, Path]:\n",
    "    csvs = sorted([v for v in data_path.ls() if v.name.endswith('.csv')])\n",
    "    csv_names = CSV_NAMES if csv_names is None else csv_names\n",
    "    return {_name: [_csv for _csv in csvs if _csv.name.startswith(_name)][0] \n",
    "            for _name in csv_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = get_csvs(data_path)\n",
    "csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert len(csvs) == len(CSV_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting basic $X$ and $y$ in train and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to inspect:\n",
    "- NaNs\n",
    "- $y$ distribution\n",
    "- compressibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get  compressed $X$ and $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_core_Xy(path:Path, nrows:int=None) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, parse_dates=['timestamp'], nrows=nrows)\n",
    "    return df_shrink(df, int2uint=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the core of the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train = get_core_Xy(csvs['train'])\n",
    "display(train.head(), train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test = get_core_Xy(csvs['test'])\n",
    "display(test.head(), test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert set(train['meter'].unique()) == set(test['meter'].unique())\n",
    "assert set(train['building_id'].unique()) == set(test['building_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def show_nans(df:pd.DataFrame):\n",
    "    nans = []\n",
    "    for col in df.columns:\n",
    "        nans.append({\n",
    "            'nans count': df[col].isna().sum(), \n",
    "            'col':col,\n",
    "            'nans %': df[col].isna().sum() / len(df) * 100,\n",
    "        })\n",
    "    return pd.DataFrame(nans).sort_values('nans count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_nans = show_nans(train)\n",
    "train_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert np.allclose(train_nans['nans count'].values, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_nans = show_nans(test)\n",
    "test_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert np.allclose(test_nans['nans count'].values, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[dep_var].describe(percentiles=[.05,.10,.25,.50,.75,.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding: ~10% of all `dep_var` values are in the vicinity of 0 and there is an outlier at 2.19e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train[dep_var] > 1e6).sum() / len(train) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['logp1'] = np.log10(train[dep_var] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "px.histogram(train.sample(10000), x='logp1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "px.histogram(train.sample(10000), x='logp1', facet_row='meter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding:\n",
    "- abnormally many 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('meter')[dep_var].describe(percentiles=[.05,.10,.25,.50,.75,.95]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding:\n",
    "- 10% of meter 1 & 2 are near 0\n",
    "- 25% of meter 3 are near 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seasonality of 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.isclose(train[dep_var], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[mask, 'timestamp'].sample(10000).dt.hour.plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(train.loc[mask, :]\n",
    "             .sample(10000)\n",
    "             .assign(hour=lambda x: x['timestamp'].dt.month),\n",
    "             x='hour',\n",
    "             facet_row='meter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding:\n",
    "- hour, day of week, day of month: not really a trend on global or meter level for the frequency of zeros\n",
    "- month: more zeros during summer for meter 2 & 3, less zeros for meter 0 from month 6 onwards, less zeros for meter 1 between month 6 and 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Site, building and meter frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['meter'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['meter'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['building_id'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['building_id'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the building info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_building_X(path:Path):\n",
    "    # TODO: year_built and floor_count actually are discrete values but contain nans\n",
    "    # test if 'Int' dtype would work or if it breaks the things downstream\n",
    "    df_building = pd.read_csv(path)\n",
    "    return df_shrink(df_building, int2uint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "building = get_building_X(csvs['building'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert building['building_id'].nunique() == len(building)\n",
    "assert set(train['building_id'].unique()) == set(building['building_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_nans = show_nans(building)\n",
    "building_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert np.allclose(building_nans['nans count'].values, [1094, 774, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting weather info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_weather_X(path:Path):\n",
    "    # TODO: cloud_coverage, wind_direction could be Int\n",
    "    df = pd.read_csv(path, parse_dates=['timestamp'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "weather_train = get_weather_X(csvs['weather_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert set(weather_train['site_id'].unique()) == set(building['site_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train_nans = show_nans(weather_train)\n",
    "weather_train_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert np.allclose(weather_train_nans.iloc[-2:]['nans count'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "weather_test = get_weather_X(csvs['weather_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert set(weather_test['site_id'].unique()) == set(building['site_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_test_nans = show_nans(weather_test)\n",
    "weather_test_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "assert np.allclose(weather_test_nans.iloc[-2:]['nans count'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "len(train.join(building.set_index('building_id'), on='building_id',\n",
    "           how='left').join(weather_train.set_index(['site_id', 'timestamp']), on=['site_id', 'timestamp'], how='left'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "len(pd.merge(pd.merge(train, building, on='building_id', how='left'),\n",
    "    weather_train, on=['site_id', 'timestamp'], how='left'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train = pd.read_csv(train_csv, parse_dates=['timestamp'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test = pd.read_csv(test_csv, parse_dates=['timestamp'])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train), len(test), len(test)/len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding:\n",
    "- test samples ~2x train samples\n",
    "- train samples ~2mio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "weather_train = pd.read_csv(train_weather_csv)\n",
    "weather_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "weather_test = pd.read_csv(test_weather_csv)\n",
    "weather_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "building = pd.read_csv(meta_csv)\n",
    "building.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train), len(weather_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many data points each building, meter, site, building type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['building_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "px.box(train.groupby('building_id').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train.groupby('meter').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "px.box(weather.groupby('site_id').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train.join(building.loc[:,['building_id', 'primary_use']], on='building_id', rsuffix='_building').groupby('primary_use').size().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding: \n",
    "- buildings vary with data points significantly\n",
    "- sites vary barely with data points\n",
    "- meter vary with data points by 10x between least and most data points\n",
    "- `primary_use`: Religious worship 32k, Education 8.1mio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomalies: meter reading, weather, building properties, gaps in the time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### meter readings (output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### counting number of meter readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('meter').()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['timestamp'].unique()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_ts = pd.date_range(train['timestamp'].min(), train['timestamp'].max(), freq='60T')\n",
    "ideal_ts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ideal_ts), train['timestamp'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding: \n",
    "- the number of timestamps in the training set matches the expected number of timestamps of 1hour intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = train.groupby('timestamp').size()\n",
    "test_counts = test.groupby('timestamp').size()\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Scatter(x=train_counts.index, y=train_counts.values, name='train'),\n",
    "    go.Scatter(x=test_counts.index, y=test_counts.values, name='test'),\n",
    "], layout=go.Layout(title='Data point count v time: train v test'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding: \n",
    "- meter counts inconsistent vs time for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### meter value trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['meter'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No NaNs in the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_counts = (train.dropna(subset=['meter']).groupby(['timestamp', 'meter'])\n",
    "                .agg(**{\n",
    "                    'mean': pd.NamedAgg('meter_reading', np.mean),\n",
    "                    'median': pd.NamedAgg('meter_reading', np.median),\n",
    "                    '5%': pd.NamedAgg('meter_reading', lambda x: np.percentile(x, 5)),\n",
    "                    '95%': pd.NamedAgg('meter_reading', lambda x: np.percentile(x, 95)),\n",
    "                }).unstack(level=-1))\n",
    "train_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for meter in [0,1,2,3]:\n",
    "    tmp = train_counts.loc[:,pd.IndexSlice[:,meter]]\n",
    "    tmp.columns = tmp.columns.droplevel(level=1)\n",
    "    tmp = tmp.reset_index()\n",
    "    \n",
    "    fig = go.Figure(data=[\n",
    "        go.Scatter(x=tmp['timestamp'], y=tmp['5%'], mode='lines', name='5%'),\n",
    "        go.Scatter(x=tmp['timestamp'], y=tmp['95%'], mode='lines', fill='tonexty', name='5% - 95%'),\n",
    "        go.Scatter(x=tmp['timestamp'], y=tmp['mean'], mode='lines', name='mean'),\n",
    "        go.Scatter(x=tmp['timestamp'], y=tmp['median'], mode='lines', name='median'),\n",
    "    ], layout=go.Layout(title=f'meter: {meter}'))\n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "meter map: `{0: electricity, 1: chilledwater, 2: steam, 3: hotwater}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding:\n",
    "- the 4 meter types have quite different time behaviors\n",
    "- meters 0 & 1 have a seasonabl behavior based on the weekday (but much stronger for meter 0 than 1)\n",
    "- meter 2 has measurement anomalies has significant anomalous time periods  (median exceeds the 95% values)\n",
    "- meter 2 & 3 have seasonal effect based on the time of year it seems "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for meter in [0,1,2,3]:\n",
    "    tmp = train.loc[train['meter']==meter, :].sort_values('meter_reading', ascending=False)\n",
    "    print('meter', meter)\n",
    "    display(tmp.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### building properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building['in_train'] = building['building_id'].isin(train['building_id'])\n",
    "building['in_test'] = building['building_id'].isin(test['building_id'])\n",
    "building.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building.groupby(['in_train', 'in_test']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(building['square_feet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(building['year_built'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(building['floor_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding:\n",
    "- `floor_count`, `year_built` and `square_feet` seem reasonable overall\n",
    "- all buildings in train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weather properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = weather_train.columns.values[2:]\n",
    "weather_train.loc[:,cols].isna().sum() / len(weather_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding:\n",
    "- `cloud_coverage` 50% NaNs\n",
    "- `precip_depth_1_hr` 35.9% NaNs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for col in cols:\n",
    "    tmp = (weather_train.dropna(subset=[col]).groupby(['timestamp'])\n",
    "              .agg(**{\n",
    "                  'mean': pd.NamedAgg(col, np.mean,),\n",
    "                  'median': pd.NamedAgg(col, np.median),\n",
    "                  '5%': pd.NamedAgg(col, lambda x: np.percentile(x, 5)),\n",
    "                  '95%': pd.NamedAgg(col, lambda x: np.percentile(x, 95)),\n",
    "              }).reset_index())\n",
    "    display(tmp.head())\n",
    "    \n",
    "    fig = go.Figure(data=[\n",
    "        go.Scatter(x=tmp['timestamp'], y=tmp['5%'], mode='lines', name='5%'),\n",
    "        go.Scatter(x=tmp['timestamp'], y=tmp['95%'], mode='lines', fill='tonexty', name='5% - 95%'),\n",
    "        go.Scatter(x=tmp['timestamp'], y=tmp['mean'], mode='lines', name='mean'),\n",
    "        go.Scatter(x=tmp['timestamp'], y=tmp['median'], mode='lines', name='median'),\n",
    "    ], layout=go.Layout(title=f'column: {col}'))\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding:\n",
    "- temperatures $\\Rightarrow$ buildings predomonantly in the northern hemisphere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class InspectTimeseries:\n",
    "    def __init__(self, train:pd.DataFrame, building:pd.DataFrame=None,\n",
    "                 weather:pd.DataFrame=None):\n",
    "        self.dep_var = 'meter_reading'\n",
    "        self.df = train\n",
    "        self.building = building\n",
    "        self.weather = weather\n",
    "        self.combos = list(zip(*train.loc[:,['building_id', 'meter']]\n",
    "                       .drop_duplicates()\n",
    "                       .values.T))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "it = InspectTimeseries(train, building=building,\n",
    "                       weather=weather_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def init_widgets(self:InspectTimeseries):\n",
    "    \n",
    "    self.int_txt_meter = widgets.IntText(min=self.df['meter'].min(), \n",
    "                                         max=self.df['meter'].max(),\n",
    "                                         description='Meter')\n",
    "    self.int_txt_bid = widgets.IntText(min=self.df['building_id'].min(), \n",
    "                                       max=self.df['building_id'].max(),\n",
    "                                       description='building id')\n",
    "    \n",
    "    self.run_btn = widgets.Button(description='plot')\n",
    "    self.run_btn.on_click(self.click_boldly)\n",
    "    self.selection_mode = widgets.Dropdown(description='selection', \n",
    "                                           value='all', \n",
    "                                           options=['all', 'random', 'filled_weeks', 'outlying'])\n",
    "    self.out_wdg = widgets.Output()\n",
    " \n",
    "\n",
    "@patch\n",
    "def inspect_boldly(self:InspectTimeseries):\n",
    "    if not hasattr(self, 'switch_btn'):\n",
    "        self.init_widgets()\n",
    "    return widgets.VBox([self.int_txt_meter, \n",
    "                         self.int_txt_bid, \n",
    "                         self.selection_mode,\n",
    "                         self.run_btn, self.out_wdg])\n",
    "\n",
    "@patch\n",
    "def click_boldly(self:InspectTimeseries, change):\n",
    "    self.out_wdg.clear_output()\n",
    "    meter = self.int_txt_meter.value\n",
    "    bid = self.int_txt_bid.value\n",
    "    \n",
    "    with self.out_wdg:\n",
    "        print(f'Selected: meter {meter} bid {bid}')\n",
    "        if (bid, meter) not in self.combos:\n",
    "            print('Combination not in the training set ðŸ¥´')\n",
    "        else:\n",
    "            self.plot_boldly(meter=meter, bid=bid).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def select_boldly_all(self:InspectTimeseries, df_plot:pd.DataFrame):\n",
    "    return df_plot.assign(label='all')\n",
    "\n",
    "@patch\n",
    "def select_boldly_random(self:InspectTimeseries, df_plot:pd.DataFrame):\n",
    "    mask_random = np.random.choice([True,False], size=len(df_plot))\n",
    "    return pd.concat((\n",
    "        (df_plot.loc[~mask_random, ['timestamp', self.dep_var]]\n",
    "         .assign(label='one')),\n",
    "        (df_plot.loc[mask_random, ['timestamp', self.dep_var]]\n",
    "         .assign(label='two')),\n",
    "    ),ignore_index=True)\n",
    "        \n",
    "\n",
    "@patch\n",
    "def select_boldly_filled_weeks(self:InspectTimeseries, df_plot:pd.DataFrame):\n",
    "    wks = (df_plot.groupby(pd.Grouper(key='timestamp', freq='W-MON'))[self.dep_var]\n",
    "           .describe(percentiles=[.05, .95]))\n",
    "\n",
    "    w_range = pd.date_range(df_plot['timestamp'].dt.date.min()-pd.Timedelta(7,unit='w'), df_plot['timestamp'].dt.date.max()+pd.Timedelta(7,unit='d'), freq='W-MON')\n",
    "    \n",
    "    df_plot['week'] = [v.right for v in pd.cut(df_plot['timestamp'], w_range)]\n",
    "    \n",
    "    df_plot = df_plot.join(wks.loc[:,['5%', '95%']], on='week')\n",
    "    mask_drop = np.isclose(df_plot['5%'], df_plot['95%'])\n",
    "    return pd.concat((\n",
    "        (df_plot.loc[mask_drop, ['timestamp', self.dep_var]]\n",
    "         .assign(label='constant')),\n",
    "        (df_plot.loc[~mask_drop, ['timestamp', self.dep_var]]\n",
    "         .assign(label='not constant')),\n",
    "    ),ignore_index=True)\n",
    "\n",
    "@patch\n",
    "def select_boldly_outlying(self:InspectTimeseries, df_plot:pd.DataFrame):\n",
    "    \n",
    "    s = df_plot[self.dep_var].describe()\n",
    "    threshold = s['50%'] + (s['75%'] - s['50%']) * 10\n",
    "        \n",
    "    mask = df_plot[self.dep_var] > threshold\n",
    "    return pd.concat((\n",
    "        (df_plot.loc[~mask, ['timestamp', self.dep_var]]\n",
    "         .assign(label='normal')),\n",
    "        (df_plot.loc[mask, ['timestamp', self.dep_var]]\n",
    "         .assign(label=f'outlier {mask.sum()}')),\n",
    "    ),ignore_index=True)\n",
    "    \n",
    "@patch\n",
    "def plot_boldly(self:InspectTimeseries,\n",
    "                meter:int=None, bid:int=None):\n",
    "    \n",
    "    \n",
    "    assert (meter is not None and bid is not None)\n",
    "        \n",
    "    mask = (self.df['meter']==int(meter)) & (self.df['building_id']==int(bid))\n",
    "    \n",
    "    \n",
    "    df_plot = self.df.loc[mask, ['timestamp', self.dep_var]]\n",
    "    \n",
    "    df_plot = getattr(self, f'select_boldly_{self.selection_mode.value}')(df_plot)\n",
    "    \n",
    "    \n",
    "    fig = px.scatter(df_plot, x='timestamp',\n",
    "                     y=self.dep_var, color='label',\n",
    "                     title=f'meter = {meter}, building_id = {bid}')\n",
    "#     fig.update_traces(line=dict(color=\"Black\", width=.4))\n",
    "    fig.update_traces(marker=dict(size=1.5)) # ,color='Black'\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "it.inspect_boldly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38_fastai]",
   "language": "python",
   "name": "conda-env-py38_fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
